# Bias UnderminingAccuracy: A Deep Learning Study on Race and Chest X-ray Diagnosis
## Prerna Joshi CS 4620 Senior Project Report 
### Under Supervision of Prof Amar Raheja
 ### California State Polytechnic University, Pomona, California



This study investigates the presence of racial bias in deep learning models used for chest X-ray (CXR) diagnosis, with a focus on how model performance varies across demographic groups. Using the CheXpert dataset, two convolutional neural network (CNN) models based on the ResNet-18 architecture were trained: one on a racially homogeneous dataset (White-identifying patients only/Model A), and another on a diverse, mixed-race dataset(Model B. The models were then evaluated using Area Under the Curve (AUC) scores across 14 disease categories to examine their diagnostic accuracy on both same-race(Test A) and different-race(Test B) test sets. The results revealed that models trained on homogeneous data tend to underperform when diagnosing patients from different racial backgrounds, raising concerns about fairness, generalizability, and patient safety in medical AI applications. This paper underscores the urgent need to incorporate demographic diversity into training datasets to reduce bias and promote equity in AI-driven diagnostic tools.Model A showed notable performance degradation when moving from Test A to Test B. For example, AUC scores for Pneumothorax dropped from 0.8210 to 0.7853, Cardiomegaly from 0.8069 to 0.8016, and Lung Opacity from 0.7014 to 0.6707. While average AUC on Test A was approximately 0.738, it declined to around 0.725 on Test B—highlighting poor generalization and suggesting the model had learned race-specific features that did not transfer well across demographic lines. By contrast, Model B demonstrated more consistent performance across both test sets. On Test B, it achieved AUC scores of 0.8210 for Cardiomegaly, 0.8135 for Pneumothorax, and 0.6621 for Lung Opacity, closely matching its stable performance on Test A, where the scores were 0.8051, 0.8042, and 0.6829 respectively for these diseases. This consistency indicates that diverse training data improves model robustness and fairness across patient populations. These results reinforce the urgent need to incorporate demographic diversity into training datasets. Without it, diagnostic models risk perpetuating racial, age or other demographic bias and delivering unequal care—raising critical concerns about fairness, safety, and equity in medical AI diagnostic systems.
